{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "V 's en Big Data",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR2x5gVm7d5M",
        "colab_type": "text"
      },
      "source": [
        "# ***V's EN BIG DATA***\n",
        "\n",
        "El consenso general del día es que hay atributos específicos que definen big data. En la mayoría de los círculos de datos grandes, estos se denominan las cuatro V: volumen, variedad, velocidad y veracidad. (Puede considerar un quinto V, valor).\n",
        "\n",
        "\n",
        "* **Volumen**\n",
        "\n",
        "  La característica principal que hace que los datos sean \"grandes\" es el gran volumen.\n",
        "\n",
        "  Este volumen presenta el desafío más inmediato para las estructuras de TI convencionales. Requiere almacenamiento escalable y un enfoque distribuido para las consultas. Muchas empresas ya tienen grandes cantidades de datos archivados, tal vez en forma de registros, pero no tienen la capacidad de procesarlos.\n",
        "\n",
        "  Suponiendo que los volúmenes de datos son más grandes de lo que pueden hacer frente a las infraestructuras de bases de datos relacionales convencionales, las opciones de procesamiento se dividen ampliamente en una elección entre arquitecturas de procesamiento masivamente paralelas (almacenes de datos o bases de datos como Greenplum) y soluciones basadas en Apache Hadoop. Esta elección a menudo se basa en el grado en que una de las otras \"V\" - variedad - entra en juego. Por lo general, los enfoques de almacenamiento de datos implican esquemas predeterminados, que se adaptan a un conjunto de datos regular y de evolución lenta. Apache Hadoop, por otro lado, no establece condiciones en la estructura de los datos que puede procesar.\n",
        "\n",
        "* **Velocidad**\n",
        "\n",
        "  La importancia de la velocidad de los datos, la tasa creciente a la que los datos fluyen hacia una organización, ha seguido un patrón similar al del volumen.\n",
        "\n",
        "  La era de Internet y dispositivos móviles significa que la forma en que entregamos y consumimos productos y servicios está cada vez más instrumentada, generando un flujo de datos de regreso al proveedor. Los minoristas en línea pueden compilar grandes historias de cada clic e interacción de los clientes: no solo las ventas finales. Aquellos que pueden utilizar rápidamente esa información, al recomendar compras adicionales, por ejemplo, obtienen una ventaja competitiva.\n",
        "\n",
        "  El problema no es solo la velocidad de los datos entrantes: **¿Es posible transmitir datos que se mueven rápidamente en almacenamiento masivo para lotes posteriores?**\n",
        "\n",
        "\n",
        "* **Variedad*\n",
        "\n",
        "  Raramente los datos se presentan en una forma perfectamente ordenada y lista para su procesamiento. Un tema común en los sistemas de big data es que la fuente de datos es diversa y no cae en estructuras relacionales claras. Podría ser texto de redes sociales, datos de imágenes, una fuente sin procesar directamente de una fuente de sensor. Ninguna de estas cosas viene lista para integrarse en una aplicación.\n",
        "\n",
        "  Incluso en la web, donde la comunicación de computadora a computadora debería brindar algunas garantías, la realidad de los datos es desordenada. Los diferentes navegadores envían datos diferentes, los usuarios retienen información, pueden estar utilizando diferentes versiones de software o proveedores para comunicarse con usted. Y puede apostar que si parte del proceso involucra a un ser humano, habrá error e inconsistencia.\n",
        "\n",
        "  Un uso común del procesamiento de big data es tomar datos no estructurados y extraer el significado ordenado, para consumo humano o como entrada estructurada para una aplicación. "
      ]
    }
  ]
}