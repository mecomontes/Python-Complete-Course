{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "¿Como funciona Big data?",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3IeD608EdKY",
        "colab_type": "text"
      },
      "source": [
        "# ¿Como Funciona Big Data?\n",
        "\n",
        "Podemos resumirlo en 3 simples acciones:\n",
        "\n",
        "* Integrar(ETL)\n",
        "\n",
        "**Fucnion:**\n",
        "Extrae los datos relevantes de ambos sistemas, los transforma para cumplir con los requisitos de formato del almacén de datos , luego los carga en el almacén de datos cabe mencionar que esto tiene 3 estapas:\n",
        "\n",
        "* 1 )  **Extracción** \n",
        "\n",
        "Es el proceso de recuperación de datos de una o más fuentes: en línea, física, datos heredados, datos de Salesforce y muchos otros. Después de recuperar los datos, el ETL los carga en un área de preparación y los prepara para la siguiente fase.\n",
        "\n",
        "* 2 ) La **transformación** \n",
        "\n",
        "Durante esta fase del proceso ETL, se pueden aplicar reglas y regulaciones que garanticen la calidad y accesibilidad de los datos. También puede aplicar reglas para ayudar a su empresa a cumplir con los requisitos de informes. El proceso de transformación de datos se compone de varios subprocesos:\n",
        "\n",
        "* **Limpieza:** \n",
        "\n",
        "En esta estap e resuelven las inconsistencias y los valores faltantes en los datos.\n",
        "\n",
        "\n",
        "* **Estandarización:**\n",
        "\n",
        "Las reglas de formato se aplican al conjunto de datos.\n",
        "Deduplicación: los datos redundantes se excluyen o se descartan.\n",
        "\n",
        "\n",
        "* **Verificación**:\n",
        "\n",
        " Se eliminan los datos inutilizables y se marcan las anomolias.\n",
        "Clasificación: los datos se organizan según el tipo.\n",
        "\n",
        "\n",
        "* **Otras tareas:** \n",
        "\n",
        "Se pueden aplicar reglas adicionales / opcionales para mejorar la calidad de los datos.\n",
        "La transformación generalmente se considera la parte más importante del proceso de ETL. La transformación de datos mejora la integridad de los datos y ayuda a garantizar que los datos lleguen a su nuevo destino totalmente compatibles y listos para usar.\n",
        "\n",
        "\n",
        "** CARGA DE DATOS **\n",
        "\n",
        "\n",
        "El paso final en el proceso ETL es cargar los datos recién transformados en un nuevo destino. Los datos se pueden cargar todos a la vez (carga completa) o en intervalos programados (carga incremental).\n",
        "\n",
        "**Carga completa:** \n",
        "\n",
        "En un escenario de carga completa de ETL, todo lo que proviene de la línea de ensamblaje de transformación pasa a registros nuevos y únicos en el almacén de datos. Aunque puede haber ocasiones en que esto sea útil para fines de investigación, la carga completa produce conjuntos de datos que crecen exponencialmente y pueden volverse difíciles de mantener rápidamente.\n",
        "\n",
        "**Carga incremental:**\n",
        "\n",
        "Un enfoque menos completo pero más manejable es la carga incremental. La carga incremental compara los datos entrantes con lo que ya está disponible, y solo produce registros adicionales si se encuentra información nueva y única. Esta arquitectura permite que los almacenes de datos más pequeños y menos costosos mantengan y administren la inteligencia empresarial.\n",
        "\n",
        "fuentes:\n",
        "https://blog.powerdata.es/el-valor-de-la-gestion-de-datos/bid/312589/procesos-etl-transformaci-n-en-qu-consiste\n",
        "\n",
        "https://blog.powerdata.es/el-valor-de-la-gestion-de-datos/caracteristicas-de-las-etl-tools-ideales-para-tus-necesidades"
      ]
    }
  ]
}